name: eFPS Test
permissions:
  pull-requests: write # for comment

on:
  # Build on pushes branches that have a PR (including drafts)
  pull_request:
  push:
    branches:
      # deploy reference studio on push to main (but skip running actual perf tests)
      - main

  workflow_dispatch:
    inputs:
      enable_profiler:
        description: "Enable profiler"
        required: true
        type: boolean
        default: false
      record_video:
        description: "Record video"
        required: true
        type: boolean
        default: false

jobs:
  deploy-preview:
    runs-on: ubuntu-latest
    env:
      TURBO_TOKEN: ${{ secrets.TURBO_TOKEN }}
      TURBO_TEAM: ${{ vars.TURBO_TEAM }}
    outputs:
      preview_url: ${{ steps.deploy.outputs.DEPLOY_URL }}
    steps:
      - uses: actions/checkout@v5
      - uses: pnpm/action-setup@v4
      - uses: actions/setup-node@v5
        with:
          node-version: lts/*

      - name: Install project dependencies
        run: pnpm install

      - name: Pull Vercel Environment Information
        env:
          VERCEL_ORG_ID: ${{ secrets.VERCEL_EFPS_STUDIO_ORG_ID }}
          VERCEL_PROJECT_ID: ${{ secrets.VERCEL_EFPS_STUDIO_PROJECT_ID }}
        run: |
          pnpm vercel pull \
            --yes \
            --environment=${{github.ref_name == 'main' && 'production' || 'preview'}} \
            --token=${{ secrets.VERCEL_EFPS_STUDIO_TOKEN }}

      - name: Load Vercel Env Vars into GITHUB_ENV
        uses: ./.github/actions/vercel-env
        with:
          org-id: ${{ secrets.VERCEL_EFPS_STUDIO_ORG_ID }}
          project-id: ${{ secrets.VERCEL_EFPS_STUDIO_PROJECT_ID }}
          token: ${{ secrets.VERCEL_EFPS_STUDIO_TOKEN }}
          environment: ${{github.ref_name == 'main' && 'production' || 'preview'}}
          variables: |
            SANITY_STUDIO_EFPS_EXPERIMENT_PROJECT_ID
            SANITY_STUDIO_EFPS_EXPERIMENT_DATASET
            SANITY_STUDIO_EFPS_EXPERIMENT_API_HOST

      - name: Build Experiment Studio from this branch
        env:
          SANITY_STUDIO_EFPS_EXPERIMENT_PROJECT_ID: ${{ env.SANITY_STUDIO_EFPS_EXPERIMENT_PROJECT_ID }}
          SANITY_STUDIO_EFPS_EXPERIMENT_DATASET: ${{ env.SANITY_STUDIO_EFPS_EXPERIMENT_DATASET }}
          SANITY_STUDIO_EFPS_EXPERIMENT_API_HOST: ${{ env.SANITY_STUDIO_EFPS_EXPERIMENT_API_HOST }}
          VERCEL_ORG_ID: ${{ secrets.VERCEL_EFPS_STUDIO_ORG_ID }}
          VERCEL_PROJECT_ID: ${{ secrets.VERCEL_EFPS_STUDIO_PROJECT_ID }}
          VERCEL_SANITY_API_DEPLOY_TOKEN: ${{ secrets.VERCEL_SANITY_API_DEPLOY_TOKEN }}

        run: pnpm vercel build --token=${{ secrets.VERCEL_EFPS_STUDIO_TOKEN }}

      - name: Deploy Experiment Studio
        id: deploy
        env:
          COMMIT_MESSAGE: ${{ github.event.head_commit.message || github.event.pull_request.title }}
        run: |
          echo "DEPLOY_URL=$(
            pnpm vercel deploy --prebuilt --token=${{ secrets.VERCEL_EFPS_STUDIO_TOKEN }} \
              -m githubDeployment="1" \
              -m githubCommitAuthorName="${{ github.event.sender.name || 'GitHub Actions' }}" \
              -m githubCommitMessage="$COMMIT_MESSAGE" \
              -m githubCommitOrg="${{ github.repository_owner }}" \
              -m githubCommitRef="${{ github.head_ref || github.ref_name }}" \
              -m githubCommitRepo="${{ github.event.repository.name }}" \
              -m githubCommitSha="${{ github.sha }}" \
              -m githubOrg="${{ github.repository_owner }}" \
              -m githubRepo="${{ github.event.repository.name }}" \
              -m githubCommitAuthorLogin="${{ github.event.sender.login || github.actor }}" | tail -n 1
            )" >> $GITHUB_OUTPUT

      - name: Promote to production if main
        id: promote-to-prod
        if: ${{github.ref_name == 'main'}}
        run: pnpm vercel promote "${{ steps.deploy.outputs.DEPLOY_URL }}" --token=${{ secrets.VERCEL_EFPS_STUDIO_TOKEN }}

      - name: Echo the deploy URL
        run: |
          if [ -z "${{ steps.deploy.outputs.DEPLOY_URL }}" ]; then
           echo "::error::Preview URL was not found. Deployment may have failed."
           exit 1
          fi
          echo "Preview URL: ${{ steps.deploy.outputs.DEPLOY_URL }}"

  efps-test:
    # We do not currently run in main, but we could do that if we want to compare main
    # against e.g. previous release
    if: ${{github.ref_name != 'main'}}
    timeout-minutes: 30
    runs-on: ubuntu-latest
    needs: [deploy-preview]
    env:
      TURBO_TOKEN: ${{ secrets.TURBO_TOKEN }}
      TURBO_TEAM: ${{ vars.TURBO_TEAM }}
      DEPLOY_URL: ${{ needs.deploy-preview.outputs.preview_url }}
    strategy:
      fail-fast: false
      matrix:
        # Add more shards here if needed
        shardIndex: [1, 2, 3]
        shardTotal: [3]
    steps:
      - uses: actions/checkout@v5
      - uses: pnpm/action-setup@v4
      - uses: actions/setup-node@v5
        with:
          node-version: lts/*

      - name: Add PR comment placeholder
        uses: thollander/actions-comment-pull-request@24bffb9b452ba05a4f3f77933840a6a841d1b32b # v3
        if: ${{ github.event_name == 'pull_request' }}
        with:
          comment-tag: "efps-report"
          message: |
            ### ⚡️ Editor Performance Report

            Deploying studio and running performance tests…

      - name: Install project dependencies
        run: pnpm install

      - name: Store Playwright's Version
        id: playwright-version
        run: |
          PLAYWRIGHT_VERSION=$(pnpm playwright --version | sed 's/Version //')
          echo "Playwright's Version: $PLAYWRIGHT_VERSION"
          echo "version=${PLAYWRIGHT_VERSION}" >> "$GITHUB_OUTPUT"

      - name: Cache Playwright Browsers for Playwright's Version
        id: cache-playwright-browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ steps.playwright-version.outputs.version }}-playwright-browsers

      - name: Install Playwright Browsers
        if: steps.cache-playwright-browsers.outputs.cache-hit != 'true'
        run: pnpm playwright install --with-deps

      - name: Load Vercel Env Vars into GITHUB_ENV
        uses: ./.github/actions/vercel-env
        with:
          org-id: ${{ secrets.VERCEL_EFPS_STUDIO_ORG_ID }}
          project-id: ${{ secrets.VERCEL_EFPS_STUDIO_PROJECT_ID }}
          token: ${{ secrets.VERCEL_EFPS_STUDIO_TOKEN }}
          # we don't run efps in production
          environment: preview
          variables: |
            SANITY_STUDIO_EFPS_REFERENCE_PROJECT_ID
            SANITY_STUDIO_EFPS_REFERENCE_DATASET
            SANITY_STUDIO_EFPS_REFERENCE_API_HOST
            SANITY_STUDIO_EFPS_EXPERIMENT_PROJECT_ID
            SANITY_STUDIO_EFPS_EXPERIMENT_DATASET
            SANITY_STUDIO_EFPS_EXPERIMENT_API_HOST
          secrets: |
            EFPS_SANITY_TOKEN_STAGING
            EFPS_SANITY_TOKEN_PROD

      - name: Run eFPS tests
        env:
          SANITY_STUDIO_EFPS_EXPERIMENT_PROJECT_ID: ${{ env.SANITY_STUDIO_EFPS_EXPERIMENT_PROJECT_ID }}
          SANITY_STUDIO_EFPS_EXPERIMENT_DATASET: ${{ env.SANITY_STUDIO_EFPS_EXPERIMENT_DATASET }}
          SANITY_STUDIO_EFPS_EXPERIMENT_API_HOST: ${{ env.SANITY_STUDIO_EFPS_EXPERIMENT_API_HOST }}
          SANITY_STUDIO_EFPS_REFERENCE_PROJECT_ID: ${{ env.SANITY_STUDIO_EFPS_REFERENCE_PROJECT_ID }}
          SANITY_STUDIO_EFPS_REFERENCE_DATASET: ${{ env.SANITY_STUDIO_EFPS_REFERENCE_DATASET }}
          SANITY_STUDIO_EFPS_REFERENCE_API_HOST: ${{ env.SANITY_STUDIO_EFPS_REFERENCE_API_HOST }}
          EFPS_SANITY_TOKEN_STAGING: ${{ env.EFPS_SANITY_TOKEN_STAGING }}
          EFPS_SANITY_TOKEN_PROD: ${{ env.EFPS_SANITY_TOKEN_PROD }}
          ENABLE_PROFILER: ${{ github.event.inputs.enable_profiler || false }}
          RECORD_VIDEO: ${{ github.event.inputs.record_video || false }}
          STUDIO_URL: ${{ needs.deploy-preview.outputs.preview_url }}
        run: pnpm efps:test -- -- --shard ${{ matrix.shardIndex }}/${{ matrix.shardTotal }}

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: efps-report-${{ matrix.shardIndex }}
          path: ${{ github.workspace }}/dev/efps/results/
          retention-days: 30

  merge-reports:
    if: ${{github.ref_name != 'main'}}
    needs: [efps-test]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5
      - uses: pnpm/action-setup@v4
      - uses: actions/setup-node@v5
        with:
          node-version: lts/*

      - name: remove node_modules in folder efps
        run: rm -rf ./dev/efps/node_modules && rm -rf pnpm-lock.yaml

      - name: Install project dependencies
        run: pnpm install

      - name: Download blob reports from Github Actions Artifacts
        uses: actions/download-artifact@v5
        with:
          pattern: efps-report-*
          merge-multiple: true
          path: dev/efps/results

      - name: Write report
        id: write-report
        run: pnpm efps:write:report

      - name: PR comment with report
        uses: thollander/actions-comment-pull-request@24bffb9b452ba05a4f3f77933840a6a841d1b32b # v3
        if: ${{ always() && github.event_name == 'pull_request' }}
        with:
          comment-tag: "efps-report"
          file-path: ${{ github.workspace }}/dev/efps/results/benchmark-results.md
